{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allanz/miniconda3/envs/nanodo/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-25 00:29:39.858580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742887779.876114 2360883 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742887779.881837 2360883 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742887779.897364 2360883 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742887779.897386 2360883 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742887779.897388 2360883 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742887779.897389 2360883 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "from nanodo.model_factory import *\n",
    "from nanodo.data import *\n",
    "from nanodo.configs.default import *\n",
    "from nanodo.train import *\n",
    "import numpy as np\n",
    "import orbax.checkpoint as ocp\n",
    "from orbax.checkpoint import PyTreeCheckpointer\n",
    "from flax.core import unfreeze\n",
    "import jax.numpy as jnp\n",
    "from nanodo.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allanz/miniconda3/envs/nanodo/lib/python3.11/site-packages/orbax/checkpoint/_src/serialization/type_handlers.py:1250: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "c = get_config()\n",
    "#checkpoint = \"/home/allanz/nanodo_workdir/92000.orbax-checkpoint-tmp-138\"\n",
    "checkpoint = \"/home/allanz/nanodo_workdir/90000/state\"\n",
    "params= PyTreeCheckpointer().restore(checkpoint)\n",
    "test = unfreeze(params['params'])\n",
    "params = params['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = ml_collections.config_dict.create(\n",
    "      D=512,  # model/embed dim  = qkv dim\n",
    "      F=2048,  # FF inner dimension\n",
    "      H=8,  # num attention heads\n",
    "      L=128,  # max context/sequence length (move out of config?)\n",
    "      N=6,  # number of transformer block layers\n",
    "      dtype=\"float32\",  # computation dtype.\n",
    "      fsdp_enabled=True,  # True to shard the model.\n",
    "      remat=False,  # Transformer block gradient checkpointing to save memory.\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerDo(\n",
      "    # attributes\n",
      "    docfg = DoConfig(D=512, H=8, L=128, N=6, V=32101, F=2048, kernel_init=<function variance_scaling.<locals>.init at 0x7f718bfbce00>, embed_init=<function variance_scaling.<locals>.init at 0x7f718bfbcea0>, dtype='float32', fsdp_enabled=True, remat=False)\n",
      ")\n",
      "TransformerDo(\n",
      "    # attributes\n",
      "    docfg = DoConfig(D=512, H=8, L=128, N=6, V=32101, F=2048, kernel_init=<function variance_scaling.<locals>.init at 0x7f718bfbce00>, embed_init=<function variance_scaling.<locals>.init at 0x7f718bfbcea0>, dtype='bfloat16', fsdp_enabled=True, remat=False)\n",
      ")\n",
      "TransformerDo(\n",
      "    # attributes\n",
      "    docfg = DoConfig(D=512, H=8, L=128, N=6, V=32101, F=2048, kernel_init=<function variance_scaling.<locals>.init at 0x7f718bfbce00>, embed_init=<function variance_scaling.<locals>.init at 0x7f718bfbcea0>, dtype=<class 'jax.numpy.float32'>, fsdp_enabled=True, remat=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_py_tokenizer(\"tests/testdata/sentencepiece_cc_all.32000.100extra-sentencepiece.model\")\n",
    "vocab_size = tokenizer.GetPieceSize()\n",
    "cfg = DoConfig(**test_config, V=vocab_size)  # pytype:disable=attribute-error\n",
    "# model without fsdp\n",
    "module = TransformerDo(cfg) \n",
    "print(module)\n",
    "# model with fsdp\n",
    "transformer, _ = get_model_and_loss(c, vocab_size)\n",
    "print(transformer)\n",
    "# same model but with dtype as jax.numpy.float32\n",
    "docfg = model.DoConfig(D=512, H=8, L=128, N=6, V=vocab_size, F=2048)\n",
    "m = model.TransformerDo(docfg)\n",
    "print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "_, init_rng = jax.random.split(rng)\n",
    "x = jnp.ones((8, 512), dtype= jnp.int32)\n",
    "initial_variables = jax.jit(m.init)(init_rng, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:Applying deprecated PyGrain MapOperation. Please use the grain.python.MapTransform.\n"
     ]
    }
   ],
   "source": [
    "test_set = py_batched_tfds(\n",
    "          tfds_name=\"c4_10k\",\n",
    "          split=\"train\",\n",
    "          context_size=512,\n",
    "          worker_count=0,\n",
    "          vocab_path=\"tests/testdata/sentencepiece_cc_all.32000.100extra-sentencepiece.model\",\n",
    "          batch_size = 8\n",
    "          )\n",
    "batch = next(iter(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.linen import Partitioned\n",
    "\n",
    "def make_partitioned(array, names):\n",
    "    partition_array = Partitioned(array, names = names, mesh = None)\n",
    "    return partition_array\n",
    "\n",
    "def convert_attn_blocks(params):\n",
    "    blocks = [\"blocks_0\", \"blocks_1\", \"blocks_2\", \"blocks_3\", \"blocks_4\", \"blocks_5\"]\n",
    "    switches = {\"attn_out_proj\": (None, None, 'data'), \"key\": ('data', None), \"query\":('data', None), \"value\":('data', None)}\n",
    "\n",
    "    for block in blocks:\n",
    "          for switch in switches: \n",
    "               #print(params[block][\"CausalAttn_0\"][switch][\"kernel\"])\n",
    "               params[block][\"CausalAttn_0\"][switch][\"kernel\"] = make_partitioned(params[block][\"CausalAttn_0\"][switch][\"kernel\"][\"value\"], switches[switch])\n",
    "\n",
    "def convert_Mlp(params):\n",
    "    blocks = [\"blocks_0\", \"blocks_1\", \"blocks_2\", \"blocks_3\", \"blocks_4\", \"blocks_5\"]\n",
    "    switches = {\"Dense_0\": ('data', None), \"Dense_1\": ('data', None)}\n",
    "\n",
    "    for block in blocks:\n",
    "          for switch in switches: \n",
    "               #print(params[block][\"Mlp_0\"][switch][\"kernel\"])\n",
    "               params[block][\"Mlp_0\"][switch][\"kernel\"] = make_partitioned(params[block][\"Mlp_0\"][switch][\"kernel\"][\"value\"], switches[switch])\n",
    "\n",
    "\n",
    "def convert_embed(params):\n",
    "    params[\"embed\"][\"embedding\"] = make_partitioned(params[\"embed\"][\"embedding\"][\"value\"], (None, 'data'))\n",
    "\n",
    "def convert_pos_embed(params):\n",
    "    params[\"pos_embed\"][\"embedding\"] = make_partitioned(params[\"pos_embed\"][\"embedding\"][\"value\"], (None, 'data'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_attn_blocks(params)\n",
    "convert_Mlp(params)\n",
    "convert_embed(params)\n",
    "convert_pos_embed(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 512, 32101)\n",
      "[[[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]]\n"
     ]
    }
   ],
   "source": [
    "logits = transformer.apply(initial_variables, x)\n",
    "print(logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 512, 32101)\n",
      "[[[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]\n",
      "\n",
      " [[nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  ...\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]\n",
      "  [nan nan nan ... nan nan nan]]]\n"
     ]
    }
   ],
   "source": [
    "logits = transformer.apply({\"params\":params}, x)\n",
    "print(logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfg = model.DoConfig(D=128, H=16, L=256, N=4, V=1024, F=4 * 4)\n",
    "m = model.TransformerDo(docfg)\n",
    "rng = jax.random.PRNGKey(42)\n",
    "_, init_rng = jax.random.split(rng)\n",
    "input_shape = (2, 256)\n",
    "x = jnp.ones(input_shape, dtype=jnp.int32)\n",
    "initial_variables_new = jax.jit(m.init)(init_rng, x)\n",
    "metrics = metrics_lib.Average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 256, 1024)\n",
      "[[[-0.7536661   1.053213   -0.9188787  ...  0.93903595  1.8903488\n",
      "   -0.03408347]\n",
      "  [-0.8577212   1.9001383  -0.05233513 ...  1.1050556   1.8848469\n",
      "   -0.76812565]\n",
      "  [-0.63099265  1.6759     -0.31756437 ...  1.3335733   1.5211788\n",
      "   -0.34489128]\n",
      "  ...\n",
      "  [-0.35996583  1.1647023  -0.72296077 ...  1.7744749   0.7932828\n",
      "    0.21230151]\n",
      "  [-0.36727864  1.2750794  -0.62616616 ...  1.8489721   0.8271866\n",
      "    0.17445332]\n",
      "  [-0.19379218  1.2730883  -0.5247805  ...  1.7327049   0.7116135\n",
      "    0.30874372]]\n",
      "\n",
      " [[-0.7536661   1.053213   -0.9188787  ...  0.93903595  1.8903488\n",
      "   -0.03408347]\n",
      "  [-0.8577212   1.9001383  -0.05233513 ...  1.1050556   1.8848469\n",
      "   -0.76812565]\n",
      "  [-0.63099265  1.6759     -0.31756437 ...  1.3335733   1.5211788\n",
      "   -0.34489128]\n",
      "  ...\n",
      "  [-0.35996583  1.1647023  -0.72296077 ...  1.7744749   0.7932828\n",
      "    0.21230151]\n",
      "  [-0.36727864  1.2750794  -0.62616616 ...  1.8489721   0.8271866\n",
      "    0.17445332]\n",
      "  [-0.19379218  1.2730883  -0.5247805  ...  1.7327049   0.7116135\n",
      "    0.30874372]]]\n"
     ]
    }
   ],
   "source": [
    "logits = m.apply(initial_variables_new, x)\n",
    "print(logits.shape)\n",
    "print(logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanodo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
